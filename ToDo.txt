1) Запихнуть хеши в Массив
2) сравнивать на равенство (помечать дубликаты ID шником?)
3) Должен работать с ярлыками и другими видами link'ов корректно (не удалять оригиналы, считая что ярплык это его копия)

=========
распаралелирвание
обработка аргументов утилиты:
	рекурс\не рекурс
	сравнивать две (и более) папки на дубликаты ( и различия заодно (?) )
		слить [и выделить разность (хз) ]

GUI?

возможность удалять дубликаты так:
{
/1/A.txt
/2/A.txt
/1/2/A.txt

/1/B.txt
/2/B.txt
/1/2/B.txt

Оставить один экземпляр дубликатов которые самые страые/новые \ лежат в папке X (выбрать)
}


сделать супер быстрой (через sum by ассеблер? Смотри как он собираеться в асм \ профилируй ...)



=======

А стоит ли делать если уже есть? Сделаю лучше и удобней для себя
https://ru.wikipedia.org/wiki/Fdupes
https://github.com/jbruchon/jdupes

и просто для практики в раст